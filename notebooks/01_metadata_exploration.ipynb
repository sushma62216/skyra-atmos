{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOAA GHCN Metadata Exploration\n",
    "\n",
    "This notebook explores the metadata files from the NOAA Global Historical Climatology Network (GHCN) dataset stored in S3.\n",
    "\n",
    "**Data Source:** `s3://noaa-ghcn-pds/`\n",
    "\n",
    "**Metadata Files:**\n",
    "- `ghcnd-stations.txt` - Weather station locations and info\n",
    "- `ghcnd-countries.txt` - Country code mappings\n",
    "- `ghcnd-states.txt` - US state/Canadian province codes\n",
    "- `ghcnd-inventory.txt` - Data availability per station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install pandas s3fs fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "from io import StringIO\n",
    "\n",
    "# S3 filesystem (no credentials needed for public bucket)\n",
    "S3_BUCKET = 's3://noaa-ghcn-pds'\n",
    "fs = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Countries Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read countries file (format: 2-char code + space + country name)\n",
    "with fs.open('noaa-ghcn-pds/ghcnd-countries.txt', 'r') as f:\n",
    "    countries_raw = f.read()\n",
    "\n",
    "countries = pd.DataFrame([\n",
    "    {'country_code': line[:2], 'country_name': line[3:].strip()}\n",
    "    for line in countries_raw.strip().split('\\n')\n",
    "])\n",
    "\n",
    "print(f\"Total countries: {len(countries)}\")\n",
    "countries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all countries\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. States/Provinces Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read states file (format: 2-char code + space + state name)\n",
    "with fs.open('noaa-ghcn-pds/ghcnd-states.txt', 'r') as f:\n",
    "    states_raw = f.read()\n",
    "\n",
    "states = pd.DataFrame([\n",
    "    {'state_code': line[:2], 'state_name': line[3:].strip()}\n",
    "    for line in states_raw.strip().split('\\n')\n",
    "])\n",
    "\n",
    "print(f\"Total states/provinces: {len(states)}\")\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stations Metadata\n",
    "\n",
    "Fixed-width format:\n",
    "- Columns 1-11: Station ID\n",
    "- Columns 13-20: Latitude\n",
    "- Columns 22-30: Longitude  \n",
    "- Columns 32-37: Elevation (meters)\n",
    "- Columns 39-40: State code\n",
    "- Columns 42-71: Station name\n",
    "- Columns 73-75: GSN flag\n",
    "- Columns 77-79: HCN/CRN flag\n",
    "- Columns 81-85: WMO ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stations file (fixed-width format)\n",
    "with fs.open('noaa-ghcn-pds/ghcnd-stations.txt', 'r') as f:\n",
    "    stations_raw = f.read()\n",
    "\n",
    "stations = pd.read_fwf(\n",
    "    StringIO(stations_raw),\n",
    "    colspecs=[\n",
    "        (0, 11),    # ID\n",
    "        (12, 20),   # LATITUDE\n",
    "        (21, 30),   # LONGITUDE\n",
    "        (31, 37),   # ELEVATION\n",
    "        (38, 40),   # STATE\n",
    "        (41, 71),   # NAME\n",
    "        (72, 75),   # GSN_FLAG\n",
    "        (76, 79),   # HCN_CRN_FLAG\n",
    "        (80, 85)    # WMO_ID\n",
    "    ],\n",
    "    names=['station_id', 'latitude', 'longitude', 'elevation', 'state', 'name', 'gsn_flag', 'hcn_crn_flag', 'wmo_id']\n",
    ")\n",
    "\n",
    "print(f\"Total stations: {len(stations):,}\")\n",
    "stations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station statistics\n",
    "print(\"Station Statistics:\")\n",
    "print(f\"  Total stations: {len(stations):,}\")\n",
    "print(f\"  Elevation range: {stations['elevation'].min():.1f}m to {stations['elevation'].max():.1f}m\")\n",
    "print(f\"  Latitude range: {stations['latitude'].min():.2f} to {stations['latitude'].max():.2f}\")\n",
    "print(f\"  Longitude range: {stations['longitude'].min():.2f} to {stations['longitude'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations by country (first 2 chars of station_id = country code)\n",
    "stations['country_code'] = stations['station_id'].str[:2]\n",
    "stations_by_country = stations.groupby('country_code').size().reset_index(name='station_count')\n",
    "stations_by_country = stations_by_country.merge(countries, on='country_code', how='left')\n",
    "stations_by_country = stations_by_country.sort_values('station_count', ascending=False)\n",
    "\n",
    "print(\"Top 20 countries by number of stations:\")\n",
    "stations_by_country.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US stations by state\n",
    "us_stations = stations[stations['country_code'] == 'US'].copy()\n",
    "us_by_state = us_stations.groupby('state').size().reset_index(name='station_count')\n",
    "us_by_state = us_by_state.merge(states, left_on='state', right_on='state_code', how='left')\n",
    "us_by_state = us_by_state.sort_values('station_count', ascending=False)\n",
    "\n",
    "print(f\"Total US stations: {len(us_stations):,}\")\n",
    "us_by_state.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inventory Metadata\n",
    "\n",
    "Shows what data elements are available for each station and the date range.\n",
    "\n",
    "Fixed-width format:\n",
    "- Columns 1-11: Station ID\n",
    "- Columns 13-20: Latitude\n",
    "- Columns 22-30: Longitude\n",
    "- Columns 32-35: Element (TMAX, TMIN, PRCP, etc.)\n",
    "- Columns 37-40: First year\n",
    "- Columns 42-45: Last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read inventory file (fixed-width format)\n",
    "with fs.open('noaa-ghcn-pds/ghcnd-inventory.txt', 'r') as f:\n",
    "    inventory_raw = f.read()\n",
    "\n",
    "inventory = pd.read_fwf(\n",
    "    StringIO(inventory_raw),\n",
    "    colspecs=[\n",
    "        (0, 11),    # ID\n",
    "        (12, 20),   # LATITUDE\n",
    "        (21, 30),   # LONGITUDE\n",
    "        (31, 35),   # ELEMENT\n",
    "        (36, 40),   # FIRST_YEAR\n",
    "        (41, 45)    # LAST_YEAR\n",
    "    ],\n",
    "    names=['station_id', 'latitude', 'longitude', 'element', 'first_year', 'last_year']\n",
    ")\n",
    "\n",
    "print(f\"Total inventory records: {len(inventory):,}\")\n",
    "inventory.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available data elements\n",
    "elements = inventory.groupby('element').agg(\n",
    "    station_count=('station_id', 'nunique'),\n",
    "    earliest_year=('first_year', 'min'),\n",
    "    latest_year=('last_year', 'max')\n",
    ").reset_index().sort_values('station_count', ascending=False)\n",
    "\n",
    "print(\"Data elements available:\")\n",
    "print(\"\\nCommon elements:\")\n",
    "print(\"  TMAX = Maximum temperature\")\n",
    "print(\"  TMIN = Minimum temperature\")\n",
    "print(\"  PRCP = Precipitation\")\n",
    "print(\"  SNOW = Snowfall\")\n",
    "print(\"  SNWD = Snow depth\")\n",
    "print()\n",
    "elements.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data coverage over time\n",
    "inventory['years_of_data'] = inventory['last_year'] - inventory['first_year'] + 1\n",
    "\n",
    "print(\"Data coverage statistics:\")\n",
    "print(f\"  Earliest data: {inventory['first_year'].min()}\")\n",
    "print(f\"  Latest data: {inventory['last_year'].max()}\")\n",
    "print(f\"  Average years of data per station-element: {inventory['years_of_data'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations with longest records for core elements\n",
    "core_elements = ['TMAX', 'TMIN', 'PRCP']\n",
    "long_records = inventory[\n",
    "    (inventory['element'].isin(core_elements)) & \n",
    "    (inventory['years_of_data'] > 100)\n",
    "]\n",
    "\n",
    "print(f\"Stations with 100+ years of core data: {long_records['station_id'].nunique():,}\")\n",
    "long_records.sort_values('years_of_data', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics for Snowflake Loading\n",
    "\n",
    "Key info to consider when loading into Snowflake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"SUMMARY FOR SNOWFLAKE LOADING\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nMetadata Tables:\")\n",
    "print(f\"  countries:  {len(countries):,} rows\")\n",
    "print(f\"  states:     {len(states):,} rows\")\n",
    "print(f\"  stations:   {len(stations):,} rows\")\n",
    "print(f\"  inventory:  {len(inventory):,} rows\")\n",
    "print(f\"\\nUnique stations: {stations['station_id'].nunique():,}\")\n",
    "print(f\"Unique elements: {inventory['element'].nunique()}\")\n",
    "print(f\"Date range: {inventory['first_year'].min()} - {inventory['last_year'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
